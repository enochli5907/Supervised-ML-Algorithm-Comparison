{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "\n",
    "For Support Vector Machine, this is the outline of what I will be doing\n",
    "<pre>\n",
    "For each dataset:\n",
    "    - read in the data and separate the labels from the data\n",
    "\n",
    "Build the GridSearchCV by defining: regularization parameter, radial width, cv, pipeline for estimator, and params\n",
    "\n",
    "Loop x3:\n",
    "    - draw 5k random samples as training data, set aside rest for testing\n",
    "    - GridSearchCV on training data to find the best hyperparameters\n",
    "    - pick the best classifier, train on all training data (as it has been fit on the last CV fold from the gridsearch)\n",
    "    - get the training and testing accuracy of this best classifier\n",
    "    - record everything final analysis\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE SURE TO RUN THIS CELL BEFORE MAKING EDITS\n",
    "\n",
    "# import libaries and set global variables\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the datasets for logistic regression\n",
    "adult = pd.read_csv('../Data/adult_clean.csv')\n",
    "cover = pd.read_csv('../Data/cover_clean.csv')\n",
    "letter_p1 = pd.read_csv('../Data/letter_p1.csv')\n",
    "letter_p2 = pd.read_csv('../Data/letter_p2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the datasets into the data (X) and labels (Y)\n",
    "adult_X = adult.iloc[:,:-1]\n",
    "adult_Y = adult.iloc[:,-1]\n",
    "\n",
    "cover_X = cover.iloc[:,:-1]\n",
    "cover_Y = cover.iloc[:,-1]\n",
    "\n",
    "letter_p1_X = letter_p1.iloc[:,:-1]\n",
    "letter_p1_Y = letter_p1.iloc[:,-1]\n",
    "\n",
    "letter_p2_X = letter_p2.iloc[:,:-1]\n",
    "letter_p2_Y = letter_p2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get regularization parameter values\n",
    "reg = [0]+list(np.geomspace(10**-7,10**3, 11))\n",
    "\n",
    "# get the radial width\n",
    "radial = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1,2]\n",
    "\n",
    "# define the cross-validation\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# build the pipeline\n",
    "pipe = Pipeline([('std', StandardScaler()),\n",
    "                 ('classifier', svm.SVC())])\n",
    "\n",
    "\n",
    "# setting up the parameters\n",
    "param = [\n",
    "    {'classifier__kernel': ['linear'], 'classifier__C': reg},\n",
    "    {'classifier__kernel': ['poly'], 'classifier__gamma': [2,3], 'classifier__C': reg},\n",
    "    {'classifier__kernel': ['rbf'], 'classifier__gamma': radial, 'classifier__C': reg}\n",
    "]\n",
    "\n",
    "# # create grid search\n",
    "clf = GridSearchCV(estimator=pipe, param_grid=param, cv=cv, n_jobs=-1, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SVM on Adult dataset for 3 trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial: 1\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# remove results file if it exists\n",
    "if os.path.isfile(\"Results/best_adult_results.txt\"):\n",
    "    os.remove(\"Results/best_adult_results.txt\")\n",
    "\n",
    "# run for 3 trials\n",
    "for trial in [1,2,3]:\n",
    "    print(\"Running trial:\",trial)\n",
    "    \n",
    "    # split the data into 5000 points for training and save the rest for testing\n",
    "    adult_X_train, adult_X_test, adult_Y_train, adult_Y_test = train_test_split(adult_X,adult_Y,\n",
    "                                                                              train_size=5000, random_state=trial)\n",
    "    \n",
    "    # fit the grid search on adult dataset and save the model\n",
    "    adult_model = clf.fit(adult_X_train, adult_Y_train)\n",
    "    joblib.dump(adult_model, 'Models/adult_model_'+str(trial)+'.pkl', compress=1)\n",
    "    \n",
    "    print(\"Fit on CV folds\")\n",
    "    \n",
    "    # fit best parameters to training set and save the model\n",
    "    best_adult_model = adult_model.fit(adult_X_train, adult_Y_train)\n",
    "    joblib.dump(best_adult_model, 'Models/best_adult_model_'+str(trial)+'.pkl', compress=1)\n",
    "    \n",
    "    print(\"Fit on training set\")\n",
    "    \n",
    "    # get the accuracy score for the testing and training data\n",
    "    train_acc = accuracy_score(y_true=adult_Y_train, y_pred=best_adult_model.predict(adult_X_train))\n",
    "    test_acc = accuracy_score(y_true=adult_Y_test, y_pred=best_adult_model.predict(adult_X_test))\n",
    "    \n",
    "    print(\"Predicted accuracy scores\")\n",
    "    \n",
    "    # write the accuracy score into a file\n",
    "    f = open(\"Results/best_adult_results.txt\", \"a\")\n",
    "    f.write('Trial '+str(trial)+\":\\n\")\n",
    "    f.write('\\tAccuracy %.2f%% (average over CV test folds)\\n' % (100 * best_adult_model.best_score_))\n",
    "    f.write('\\tBest Parameters: %s\\n' % best_adult_model.best_params_)\n",
    "    f.write('\\tTraining Accuracy: %.2f%%\\n' % (100 * train_acc))\n",
    "    f.write('\\tTest Accuracy: %.2f%%\\n\\n' % (100 * test_acc))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SVM on Cover dataset for 3 trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# remove results file if it exists\n",
    "if os.path.isfile(\"Results/best_cover_results.txt\"):\n",
    "    os.remove(\"Results/best_cover_results.txt\")\n",
    "\n",
    "# run for 3 trials\n",
    "for trial in [1,2,3]:\n",
    "    print(\"Running trial:\",trial)    # print the trial number\n",
    "\n",
    "    # split the data into 5000 points for training and save the rest for testing\n",
    "    cover_X_train, cover_X_test, cover_Y_train, cover_Y_test = train_test_split(cover_X,cover_Y,\n",
    "                                                                              train_size=5000, random_state=trial)\n",
    "    \n",
    "    # fit the grid search on cover dataset and save the model\n",
    "    cover_model = clf.fit(cover_X_train, cover_Y_train)\n",
    "    joblib.dump(cover_model, 'Models/cover_model_'+str(trial)+'.pkl', compress=1)\n",
    "    \n",
    "    # fit best parameters to training set and save the model\n",
    "    best_cover_model = cover_model.fit(cover_X_train, cover_Y_train)\n",
    "    joblib.dump(best_cover_model, 'Models/best_cover_model_'+str(trial)+'.pkl', compress=1)\n",
    "    \n",
    "    train_acc = accuracy_score(y_true=cover_Y_train, y_pred=best_cover_model.predict(cover_X_train))\n",
    "    test_acc = accuracy_score(y_true=cover_Y_test, y_pred=best_cover_model.predict(cover_X_test))\n",
    "    \n",
    "    f = open(\"Results/best_cover_results.txt\", \"a\")\n",
    "    f.write('Trial '+str(trial)+\":\\n\")\n",
    "    f.write('\\tAccuracy %.2f%% (average over CV test folds)\\n' % (100 * best_cover_model.best_score_))\n",
    "    f.write('\\tBest Parameters: %s\\n' % best_cover_model.best_params_)\n",
    "    f.write('\\tTraining Accuracy: %.2f%%\\n' % (100 * train_acc))\n",
    "    f.write('\\tTest Accuracy: %.2f%%\\n\\n' % (100 * test_acc))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SVM on Letter_p1 dataset for 3 trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# remove results file if it exists\n",
    "if os.path.isfile(\"Results/best_letter_p1_results.txt\"):\n",
    "    os.remove(\"Results/best_letter_p1_results.txt\")\n",
    "\n",
    "# run for 3 trials\n",
    "for trial in [1,2,3]:\n",
    "    print(\"Running trial:\",trial)\n",
    "\n",
    "    # split the data into 5000 points for training and save the rest for testing   \n",
    "    letter_p1_X_train, letter_p1_X_test, letter_p1_Y_train, letter_p1_Y_test = train_test_split(letter_p1_X,letter_p1_Y,\n",
    "                                                                              train_size=5000, random_state=trial)\n",
    "    \n",
    "    # fit the grid search on letter_p1 dataset and save the model\n",
    "    letter_p1_model = clf.fit(letter_p1_X_train, letter_p1_Y_train)\n",
    "    joblib.dump(letter_p1_model, 'Models/letter_p1_model_'+str(trial)+'.pkl', compress=1)\n",
    "    \n",
    "    # fit best parameters to training set and save the model\n",
    "    best_letter_p1_model = letter_p1_model.fit(letter_p1_X_train, letter_p1_Y_train)\n",
    "    joblib.dump(best_letter_p1_model, 'Models/best_letter_p1_model_'+str(trial)+'.pkl', compress=1)\n",
    "    \n",
    "    train_acc = accuracy_score(y_true=letter_p1_Y_train, y_pred=best_letter_p1_model.predict(letter_p1_X_train))\n",
    "    test_acc = accuracy_score(y_true=letter_p1_Y_test, y_pred=best_letter_p1_model.predict(letter_p1_X_test))\n",
    "    \n",
    "    f = open(\"Results/best_letter_p1_results.txt\", \"a\")\n",
    "    f.write('Trial '+str(trial)+\":\\n\")\n",
    "    f.write('\\tAccuracy %.2f%% (average over CV test folds)\\n' % (100 * best_letter_p1_model.best_score_))\n",
    "    f.write('\\tBest Parameters: %s\\n' % best_letter_p1_model.best_params_)\n",
    "    f.write('\\tTraining Accuracy: %.2f%%\\n' % (100 * train_acc))\n",
    "    f.write('\\tTest Accuracy: %.2f%%\\n\\n' % (100 * test_acc))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SVM on Letter_p2 datasets for 3 trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# remove results file if it exists\n",
    "if os.path.isfile(\"Results/best_letter_p2_results.txt\"):\n",
    "    os.remove(\"Results/best_letter_p2_results.txt\")\n",
    "    \n",
    "# run for 3 trials\n",
    "for trial in [1,2,3]:\n",
    "    print(\"Running trial:\",trial)\n",
    "    \n",
    "    # split the data into 5000 points for training and save the rest for testing\n",
    "    letter_p2_X_train, letter_p2_X_test, letter_p2_Y_train, letter_p2_Y_test = train_test_split(letter_p2_X,letter_p2_Y,\n",
    "                                                                              train_size=5000, random_state=trial)\n",
    "\n",
    "    # fit the grid search on letter_p2 dataset and save the model\n",
    "    letter_p2_model = clf.fit(letter_p2_X_train, letter_p2_Y_train)\n",
    "    joblib.dump(letter_p2_model, 'Models/letter_p2_model_'+str(trial)+'.pkl', compress=1)\n",
    "    \n",
    "    # fit best parameters to training set and save the model\n",
    "    best_letter_p2_model = letter_p2_model.fit(letter_p2_X_train, letter_p2_Y_train)\n",
    "    joblib.dump(best_letter_p2_model, 'Models/best_letter_p2_model_'+str(trial)+'.pkl', compress=1)\n",
    "    \n",
    "    train_acc = accuracy_score(y_true=letter_p2_Y_train, y_pred=best_letter_p2_model.predict(letter_p2_X_train))\n",
    "    test_acc = accuracy_score(y_true=letter_p2_Y_test, y_pred=best_letter_p2_model.predict(letter_p2_X_test))\n",
    "    \n",
    "    f = open(\"Results/best_letter_p2_results.txt\", \"a\")\n",
    "    f.write('Trial '+str(trial)+\":\\n\")\n",
    "    f.write('\\tAccuracy %.2f%% (average over CV test folds)\\n' % (100 * best_letter_p2_model.best_score_))\n",
    "    f.write('\\tBest Parameters: %s\\n' % best_letter_p2_model.best_params_)\n",
    "    f.write('\\tTraining Accuracy: %.2f%%\\n' % (100 * train_acc))\n",
    "    f.write('\\tTest Accuracy: %.2f%%\\n\\n' % (100 * test_acc))\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
