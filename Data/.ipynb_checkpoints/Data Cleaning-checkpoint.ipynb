{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "This notebook is to be used for data cleaning and preparing the data sets for selecting hyperparamters of sklearn models. The classification label will be listed as the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages and declare global variables\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "bold = '\\033[1m'\n",
    "unbold = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets and assign headers\n",
    "adult_column = [\"age\", \"workclass\", \"num_represented\", \"education\", \"education_num\", \"marital_status\", \"occupation\",\n",
    "                \"relationship\", \"race\", \"sex\", \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"country\", \"income\"]\n",
    "\n",
    "cover_column = [\"elevation\", \"aspect\", \"slope\", \"h_dist_to_water\", \"v_dist_to_water\", \"h_dist_to_road\", \"shade_am\",\n",
    "                \"shade_noon\", \"shade_pm\", \"h_dist_to_fire\", \"wilderness_area1\", \"wilderness_area2\", \"wilderness_area3\",\n",
    "                \"wilderness_area4\", 'soil_type1', 'soil_type2', 'soil_type3', 'soil_type4', 'soil_type5', 'soil_type6',\n",
    "                'soil_type7', 'soil_type8', 'soil_type9', 'soil_type10', 'soil_type11', 'soil_type12', 'soil_type13',\n",
    "                'soil_type14', 'soil_type15', 'soil_type16', 'soil_type17', 'soil_type18', 'soil_type19', 'soil_type20',\n",
    "                'soil_type21', 'soil_type22', 'soil_type23', 'soil_type24','soil_type25', 'soil_type26', 'soil_type27',\n",
    "                'soil_type28', 'soil_type29', 'soil_type30', 'soil_type31', 'soil_type32', 'soil_type33', 'soil_type34',\n",
    "                'soil_type35', 'soil_type36', 'soil_type37', 'soil_type38', 'soil_type39', 'soil_type40',  \"cover_type\"]\n",
    "\n",
    "letter_column = [\"letter\", \"x_box\", \"y_box\", \"width\", \"height\", \"total_pix\", \"x_bar\", \"y_bar\", \"x2_bar\",\n",
    "                 \"y2_bar\", \"xy_bar\", \"x2y_bar\", \"xy2_bar\", \"x_edge\", \"x_edge_y\", \"y_edge\", \"y_edge_x\"]\n",
    "\n",
    "adult = pd.read_csv('Original Data/adult.csv', names=adult_column, na_values='?')\n",
    "cover = pd.read_csv('Original Data/covtype.csv', names=cover_column, na_values='?')\n",
    "letter = pd.read_csv('Original Data/letter-recognition.csv', names=letter_column, na_values='?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAdult dataset\u001b[0m\n",
      "32561 rows, 15 attributes\n",
      "4262 missing values\n",
      "2399 rows with missing values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>num_represented</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  num_represented  education  education_num  \\\n",
       "0   39         State-gov            77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc            83311  Bachelors             13   \n",
       "2   38           Private           215646    HS-grad              9   \n",
       "3   53           Private           234721       11th              7   \n",
       "4   28           Private           338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week        country income  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the adult dataset\n",
    "print(bold+\"Adult dataset\"+unbold)\n",
    "print(\"{} rows, {} attributes\".format(adult.shape[0], adult.shape[1]))\n",
    "print(\"{} missing values\".format(adult.isnull().sum().sum()))\n",
    "print(\"{} rows with missing values\".format(adult.isnull().any(axis=1).sum()))\n",
    "adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCover dataset\u001b[0m\n",
      "581012 rows, 55 attributes\n",
      "0 missing values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation</th>\n",
       "      <th>aspect</th>\n",
       "      <th>slope</th>\n",
       "      <th>h_dist_to_water</th>\n",
       "      <th>v_dist_to_water</th>\n",
       "      <th>h_dist_to_road</th>\n",
       "      <th>shade_am</th>\n",
       "      <th>shade_noon</th>\n",
       "      <th>shade_pm</th>\n",
       "      <th>h_dist_to_fire</th>\n",
       "      <th>...</th>\n",
       "      <th>soil_type32</th>\n",
       "      <th>soil_type33</th>\n",
       "      <th>soil_type34</th>\n",
       "      <th>soil_type35</th>\n",
       "      <th>soil_type36</th>\n",
       "      <th>soil_type37</th>\n",
       "      <th>soil_type38</th>\n",
       "      <th>soil_type39</th>\n",
       "      <th>soil_type40</th>\n",
       "      <th>cover_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   elevation  aspect  slope  h_dist_to_water  v_dist_to_water  h_dist_to_road  \\\n",
       "0       2596      51      3              258                0             510   \n",
       "1       2590      56      2              212               -6             390   \n",
       "2       2804     139      9              268               65            3180   \n",
       "3       2785     155     18              242              118            3090   \n",
       "4       2595      45      2              153               -1             391   \n",
       "\n",
       "   shade_am  shade_noon  shade_pm  h_dist_to_fire  ...  soil_type32  \\\n",
       "0       221         232       148            6279  ...            0   \n",
       "1       220         235       151            6225  ...            0   \n",
       "2       234         238       135            6121  ...            0   \n",
       "3       238         238       122            6211  ...            0   \n",
       "4       220         234       150            6172  ...            0   \n",
       "\n",
       "   soil_type33  soil_type34  soil_type35  soil_type36  soil_type37  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   soil_type38  soil_type39  soil_type40  cover_type  \n",
       "0            0            0            0           5  \n",
       "1            0            0            0           5  \n",
       "2            0            0            0           2  \n",
       "3            0            0            0           2  \n",
       "4            0            0            0           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descibe the cover dataset\n",
    "print(bold+\"Cover dataset\"+unbold)\n",
    "print(\"{} rows, {} attributes\".format(cover.shape[0], cover.shape[1]))\n",
    "print(\"{} missing values\".format(cover.isnull().sum().sum()))\n",
    "cover.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mLetter dataset\u001b[0m\n",
      "20000 rows, 17 attributes\n",
      "0 missing values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>x_box</th>\n",
       "      <th>y_box</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>total_pix</th>\n",
       "      <th>x_bar</th>\n",
       "      <th>y_bar</th>\n",
       "      <th>x2_bar</th>\n",
       "      <th>y2_bar</th>\n",
       "      <th>xy_bar</th>\n",
       "      <th>x2y_bar</th>\n",
       "      <th>xy2_bar</th>\n",
       "      <th>x_edge</th>\n",
       "      <th>x_edge_y</th>\n",
       "      <th>y_edge</th>\n",
       "      <th>y_edge_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  x_box  y_box  width  height  total_pix  x_bar  y_bar  x2_bar  \\\n",
       "0      T      2      8      3       5          1      8     13       0   \n",
       "1      I      5     12      3       7          2     10      5       5   \n",
       "2      D      4     11      6       8          6     10      6       2   \n",
       "3      N      7     11      6       6          3      5      9       4   \n",
       "4      G      2      1      3       1          1      8      6       6   \n",
       "\n",
       "   y2_bar  xy_bar  x2y_bar  xy2_bar  x_edge  x_edge_y  y_edge  y_edge_x  \n",
       "0       6       6       10        8       0         8       0         8  \n",
       "1       4      13        3        9       2         8       4        10  \n",
       "2       6      10        3        7       3         7       3         9  \n",
       "3       6       4        4       10       6        10       2         8  \n",
       "4       6       6        5        9       1         7       5        10  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display how many missing values are in each dataset\n",
    "print(bold+\"Letter dataset\"+unbold)\n",
    "print(\"{} rows, {} attributes\".format(letter.shape[0], letter.shape[1]))\n",
    "print(\"{} missing values\".format(letter.isnull().sum().sum()))\n",
    "letter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Adult Dataset\n",
    "The <b>Adult dataset</b> has missing values and categorical data, so we need to remove the rows with missing data and convert all the categorical data into numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBreakdown of missing values in Adult dataset\u001b[0m\n",
      "age                   0\n",
      "workclass          1836\n",
      "num_represented       0\n",
      "education             0\n",
      "education_num         0\n",
      "marital_status        0\n",
      "occupation         1843\n",
      "relationship          0\n",
      "race                  0\n",
      "sex                   0\n",
      "capital_gain          0\n",
      "capital_loss          0\n",
      "hours_per_week        0\n",
      "country             583\n",
      "income                0\n",
      "dtype: int64\n",
      "\n",
      "\u001b[1mShape of adult with dropped rows\u001b[0m\n",
      "30162 rows, 15 attributes\n"
     ]
    }
   ],
   "source": [
    "# show breakdown of missing values\n",
    "print(bold+\"Breakdown of missing values in Adult dataset\"+unbold)\n",
    "print(adult.isnull().sum())\n",
    "\n",
    "# drop the rows with na in the adult dataset\n",
    "adult.dropna(inplace=True)\n",
    "print('\\n'+bold+\"Shape of adult with dropped rows\"+unbold)\n",
    "print(\"{} rows, {} attributes\".format(adult.shape[0], adult.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30162 rows, 105 attributes\n"
     ]
    }
   ],
   "source": [
    "# transform categorical data into binary values\n",
    "left = pd.get_dummies(adult[adult.columns[:len(adult.columns)-1]])\n",
    "\n",
    "# income <=50K is rep. as -1, >50K is rep. as 1\n",
    "right = adult['income'].replace(to_replace=['<=50K','>50K'], value=[-1,1])\n",
    "\n",
    "# adult dataset is now ready for modeling\n",
    "adult_clean = pd.concat([left,right],axis=1)\n",
    "\n",
    "# final shape of clean dataset\n",
    "print(\"{} rows, {} attributes\".format(adult_clean.shape[0], adult_clean.shape[1]))\n",
    "\n",
    "# export dataset to new csv file\n",
    "adult_clean.to_csv('Data/adult_clean.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Cover Dataset\n",
    "The <b>Cover dataset</b> is converted to numerical data by treating the largest cover as the positive and the\n",
    "rest as negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581012 rows, 55 attributes\n"
     ]
    }
   ],
   "source": [
    "# Calculate the binary data for cover type\n",
    "largest = max(cover['cover_type'].unique())\n",
    "rest = list(filter(lambda c: c != largest, cover['cover_type'].unique()))\n",
    "negCov = [-1] * len(rest)\n",
    "\n",
    "# transform the cover_type data into binary values\n",
    "cover_type = cover['cover_type'].replace(to_replace=[largest, *rest], value=[1, *negCov])\n",
    "\n",
    "# cover dataset is now ready for modeling\n",
    "cover_clean = pd.concat([cover[cover.columns[:len(cover.columns)-1]],cover_type],axis=1)\n",
    "\n",
    "# final shape of clean dataset\n",
    "print(\"{} rows, {} attributes\".format(cover.shape[0], cover.shape[1]))\n",
    "\n",
    "# export dataset to new csv file\n",
    "cover_clean.to_csv('Data/cover_clean.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Letter Dataset\n",
    "The <b>Letter dataset</b> is will be converted to numerical data in two different ways. \n",
    "\n",
    "<b>letter_p1</b> treats ”O” as positive and the remaining 25 letters as negative, yielding a very unbalanced problem. <br><b>letter_p2</b> uses letters A-M as positives and the rest as negatives, yielding a well balanced problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate out the letter column\n",
    "let = letter['letter'] \n",
    "\n",
    "# get the alphabet\n",
    "alpha = list(string.ascii_uppercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting letter_p1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate \"O\" from the rest of the alphabet\n",
    "other = list(filter(lambda a: a != \"O\", alpha))\n",
    "neg_p1 = [-1] * len(other)\n",
    "\n",
    "# transform the letter column into the p1 numerical values\n",
    "p1 = let.replace(to_replace=[\"O\", *other], value=[1,*neg_p1])\n",
    "\n",
    "# letter_p1 dataset is now ready for modeling\n",
    "letter_p1 = pd.concat([letter[letter.columns[1:]],p1],axis=1)\n",
    "\n",
    "# export dataset to new csv file\n",
    "letter_p1.to_csv('Data/letter_p1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting letter_p2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the two halfs of the alphabet\n",
    "upper = alpha[:len(alpha)//2]\n",
    "lower = alpha[len(alpha)//2:]\n",
    "pos_p2 = [1] * len(upper)\n",
    "neg_p2 = [-1] * len(lower)\n",
    "\n",
    "# transform the letter column into the p1 numerical values\n",
    "p2 = let.replace(to_replace=[*upper, *lower], value=[*pos_p2,*neg_p2])\n",
    "\n",
    "# letter_p2 dataset is now ready for modeling\n",
    "letter_p2 = pd.concat([letter[letter.columns[1:]],p2],axis=1)\n",
    "\n",
    "# export dataset to new csv file\n",
    "letter_p2.to_csv('Data/letter_p2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
